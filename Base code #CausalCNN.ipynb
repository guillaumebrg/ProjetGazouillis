{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET = np.load(\"data/dataset.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (15075059L, 161L, 1L)\n"
     ]
    }
   ],
   "source": [
    "print \"Shape :\", DATASET.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into a trainset, a validset and a testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_rate=[0.94, 0.01, 0.04], seed=123): # see preprocessing.py\n",
    "    # index = 1,2,3,...,N\n",
    "    N = dataset.shape[0]\n",
    "    index = range(dataset.shape[0])\n",
    "    # shuffle\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(index)\n",
    "    # division\n",
    "    train_rate, valid_rate, test_rate = np.cumsum(split_rate)\n",
    "    index_train = index[0:int(train_rate*N)]\n",
    "    index_valid = index[int(train_rate*N):int(valid_rate*N)]\n",
    "    index_test = index[int(valid_rate*N):int(test_rate*N)]\n",
    "    # return \n",
    "    return index_train, index_valid, index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_train, index_valid, index_test = split_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**index_train, index_valid, index_test** are such that :\n",
    "\n",
    "trainset = DATASET[index_train]\n",
    "\n",
    "validset = DATASET[index_valid]\n",
    "\n",
    "testset = DATASET[index_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACCEPTED_CHARS = params.ACCEPTED_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x80', '\\x92', '\\x98', '\\x9f', '\\xa6', '\\xe2', '\\xf0']\n"
     ]
    }
   ],
   "source": [
    "print ACCEPTED_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch2onehot(batch, D): # see preprocessing.py\n",
    "    ''' Function used during the training to encode batches.\n",
    "    Input size : (batch_size, tweet_length, 1).\n",
    "    Output size : (batch_size, tweet_length, D)'''\n",
    "    B, T = batch.shape[0:2]\n",
    "    one_hot_batch = np.zeros((B*T, D))\n",
    "    one_hot_batch[range(B*T), batch.flatten()] = 1\n",
    "    one_hot_batch = one_hot_batch.reshape((B,T,D))\n",
    "    return one_hot_batch\n",
    "\n",
    "def batch2tweet(batch, accepted_caracters, special_char=\"\"): # see preprocessing.py\n",
    "    '''Not optimized. But not used during the training : no need to be fast.'''\n",
    "    tweets = []\n",
    "    for t in batch:\n",
    "        tweet = \"\"\n",
    "        for char in t:\n",
    "            try:\n",
    "                tweet += accepted_caracters[char[0]]\n",
    "            except:\n",
    "                tweet += special_char # Special marker indicating the end of the tweet\n",
    "        tweets.append(tweet)\n",
    "    return tweets\n",
    "\n",
    "def onehot2tweet(batch, accepted_caracters, special_char=\"\"): # see preprocessing.py\n",
    "    '''Not optimized. But not used during the training : no need to be fast.'''\n",
    "    tweets = []\n",
    "    for t in batch:\n",
    "        tweet = \"\"\n",
    "        for char in t:\n",
    "            try:\n",
    "                tweet += accepted_caracters[np.where(char==1)[0][0]]\n",
    "            except:\n",
    "                tweet += special_char # Special marker indicating the end of the tweet\n",
    "        tweets.append(tweet)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char 152 from tweet 27 : [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "D = params.D  # dimension of one-hot vectors\n",
    "B = params.B  # batch size for the demo\n",
    "T = params.T  # max length of a tweet\n",
    "batch = DATASET[0:B] \n",
    "# Dataset > One-hot\n",
    "one_hot_batch = batch2onehot(batch, D)\n",
    "\n",
    "# Pick a tweet\n",
    "t = np.random.randint(B)\n",
    "# Pick a char\n",
    "c = np.random.randint(T)\n",
    "print \"Char %d from tweet %d :\"%(c,t), one_hot_batch[t][c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to, possible to go back in the \"string\" domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @c_throwed: obama the goat for this ðŸ’€\n",
      "\n",
      " https://t.co/gaznhjw7ry\n",
      "rt @c_throwed: obama the goat for this ðŸ’€\n",
      "\n",
      " https://t.co/gaznhjw7ry\n"
     ]
    }
   ],
   "source": [
    "# Using 'batch2tweet' :\n",
    "t = np.random.randint(B) # Pick a tweet\n",
    "print batch2tweet(batch, ACCEPTED_CHARS)[t]\n",
    "# or 'onehot2tweet' if the tweet has already been converted to onehot :\n",
    "print onehot2tweet(one_hot_batch, ACCEPTED_CHARS)[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, index, batch_size, D): # see preprocessing.py\n",
    "    # Init iterator and shuffling the dataset\n",
    "    count = 0\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        if count+batch_size >= len(index):\n",
    "            # Reset counter and shuffling\n",
    "            count = 0\n",
    "            np.random.shuffle(index)\n",
    "        # Get raw data\n",
    "        raw_batch = np.copy(data[index[count:(count+batch_size)]])\n",
    "        # One-hot encoding\n",
    "        one_hot_batch = batch2onehot(raw_batch, D)\n",
    "        # Remove the padding dimension\n",
    "        one_hot_batch = one_hot_batch[:,:,0:(D-1)] # s.t. padding features are full of 0s\n",
    "                                                   # and will be masked by the Masking layer\n",
    "                                                   # (see below in the model definition)\n",
    "        # Target\n",
    "        input_batch  = one_hot_batch[:, 0:-1, :]\n",
    "        target_batch = one_hot_batch[:, 1:, :] # target = 1-shifted input batch\n",
    "        del raw_batch\n",
    "        count += batch_size\n",
    "        # Yield\n",
    "        yield input_batch, target_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions used to save stuff..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save_architecture** : save the architecture of the model in a text file.\n",
    "\n",
    "**create_log** : create a text file where the loss, and other metrics will be printed using **write_log**\n",
    "\n",
    "**ModelSaver** : Custom Keras callback (https://keras.io/callbacks/). This object is given to the 'fit' (or equivalently 'fit_generator') when launching a training. It permits to control when to save weights, and underwhich name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_architecture(model, path_out): # see logging.py\n",
    "    \"\"\"\n",
    "    Based on the keras utils 'model.summary()'\n",
    "    \"\"\"\n",
    "    # Redirect the print output the a textfile\n",
    "    orig_stdout = sys.stdout\n",
    "    # and store the architecture\n",
    "    f = file(os.path.join(path_out, \"architecture.txt\"), 'w')\n",
    "    sys.stdout = f\n",
    "    model.summary()\n",
    "    # Reset the print output direction\n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "\n",
    "    open(os.path.join(path_out, \"config.json\"), 'w').write(model.to_json())\n",
    "\n",
    "\n",
    "def create_log(path, settings, filename=\"log.txt\"): # see logging.py\n",
    "    f = open(os.path.join(path, filename), \"w\")\n",
    "    f.writelines(str(settings))\n",
    "    f.writelines(\"\\n####\\nStarted on %s at %s\\n\" % (time.strftime(\"%d/%m/%Y\"), time.strftime(\"%H:%M:%S\")))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def write_log(path, string, filename=\"log.txt\"): # see logging.py\n",
    "    \"\"\"\n",
    "    Add a line at the end of a textfile.\n",
    "\n",
    "    :param path: textfile location\n",
    "    :param string: line to add\n",
    "    \"\"\"\n",
    "    # Open and Read\n",
    "    f = open(os.path.join(path, filename), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    # Adding a line\n",
    "    lines.append(string)\n",
    "    # Write\n",
    "    f = open(os.path.join(path, filename), \"w\")\n",
    "    f.writelines(lines)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "    \n",
    "class ModelSaver(Callback): # see logging.py\n",
    "    \"\"\"\n",
    "    Keras callback subclass which defines a saving procedure of the model being trained : after each epoch,\n",
    "    the last model is saved under the name 'after_random.cnn'. The best model is saved with the name 'best_model.cnn'.\n",
    "    The model after random can also be saved. And the model architecture is saved with the name 'config.network'.\n",
    "    Everything is stored using pickle.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, path_weights, monitor, verbose=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.path_weights = path_weights\n",
    "        self.monitor = monitor\n",
    "        self.best = np.Inf\n",
    "        \n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_end = time.time()\n",
    "        # get loss\n",
    "        monitor = logs.get(self.monitor)\n",
    "        # condition = True if loss decreased\n",
    "        condition = monitor < self.best\n",
    "\n",
    "        if condition:\n",
    "            # Save weights as \"best_model.weights\"\n",
    "            self.best = monitor\n",
    "            save_path = os.path.join(self.path_weights, \"best_model.weights\")\n",
    "            self.model.save_weights(save_path, overwrite=True)\n",
    "        else:\n",
    "            # Save weights as \"last_epoch.weights\"\n",
    "            save_path = os.path.join(self.path_weights, \"last_epoch.weights\")\n",
    "            self.model.save_weights(save_path, overwrite=True)\n",
    "        \n",
    "        # Log file management\n",
    "        if self.verbose > 0:\n",
    "            log_string = \"####\\nEpoch %d took %d s: \" % (epoch, int(self.epoch_end-self.epoch_start))\n",
    "            for k in logs.keys():\n",
    "                log_string += \"%s : %.4f # \" % (k, logs.get(k))\n",
    "            if condition:\n",
    "                log_string += \"\\tBEST\"\n",
    "            write_log(self.path, log_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, TimeDistributed, Dense, Activation, ZeroPadding1D, AtrousConvolution1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CausalConvolution1D(input_layer, nfilters, filter_length, atrous_rate=1, **kwargs):\n",
    "    total_length = filter_length + (filter_length-1)*(atrous_rate-1)\n",
    "    # Asymetric padding : 0 added only on the left side\n",
    "    padd = ZeroPadding1D((total_length-1,0))(input_layer)\n",
    "    # Convolution \n",
    "    conv = AtrousConvolution1D(nfilters, filter_length, atrous_rate=atrous_rate, border_mode='valid', **kwargs)(padd)\n",
    "    # Return\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(T, D, lr, nhidden, drop_rate): # see models.py\n",
    "    # Input layer\n",
    "    inputs = Input((T, D))\n",
    "    # Masking \"only-0\" input features : ZeroPadding do not support Masking\n",
    "    # masked = Masking(mask_value=0.0)(inputs)\n",
    "    # Hidden layers\n",
    "    for i in range(10):\n",
    "        if i == 0:\n",
    "            hidden  = CausalConvolution1D(inputs, 128, 11, atrous_rate=1, activation=\"relu\")\n",
    "        else:\n",
    "            hidden  = CausalConvolution1D(dropout, 128, 11, atrous_rate=1, activation=\"relu\")\n",
    "        dropout = Dropout(drop_rate)(hidden)\n",
    "    # Output layer : linear TimeDistributedDense + softmax\n",
    "    decoder = TimeDistributed(Dense(D))(dropout) # Apply the same dense layer on each timestep\n",
    "    outputs = Activation(\"softmax\") (decoder)\n",
    "\n",
    "    model = Model(input=inputs, output=outputs)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss=\"categorical_crossentropy\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = params.LR # learning rate\n",
    "model = get_model(T-1, D-1, LR, 3, 0.1) # D-1 because params.D accounts for the padding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 160, 63)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_36 (ZeroPadding1D) (None, 170, 63)       0           input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_34 (AtrousCon(None, 160, 128)      88832       zeropadding1d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_37 (ZeroPadding1D) (None, 170, 128)      0           dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_35 (AtrousCon(None, 160, 128)      180352      zeropadding1d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_38 (ZeroPadding1D) (None, 170, 128)      0           dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_36 (AtrousCon(None, 160, 128)      180352      zeropadding1d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_39 (ZeroPadding1D) (None, 170, 128)      0           dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_37 (AtrousCon(None, 160, 128)      180352      zeropadding1d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_40 (ZeroPadding1D) (None, 170, 128)      0           dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_38 (AtrousCon(None, 160, 128)      180352      zeropadding1d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_41 (ZeroPadding1D) (None, 170, 128)      0           dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_39 (AtrousCon(None, 160, 128)      180352      zeropadding1d_41[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_42 (ZeroPadding1D) (None, 170, 128)      0           dropout_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_40 (AtrousCon(None, 160, 128)      180352      zeropadding1d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_43 (ZeroPadding1D) (None, 170, 128)      0           dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_41 (AtrousCon(None, 160, 128)      180352      zeropadding1d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_44 (ZeroPadding1D) (None, 170, 128)      0           dropout_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_42 (AtrousCon(None, 160, 128)      180352      zeropadding1d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_45 (ZeroPadding1D) (None, 170, 128)      0           dropout_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_43 (AtrousCon(None, 160, 128)      180352      zeropadding1d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)             (None, 160, 128)      0           atrousconvolution1d_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_7 (TimeDistribute(None, 160, 63)       8127        dropout_43[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 160, 63)       0           timedistributed_7[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1720127\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Guillaume\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-2.7.8-64\\lock_dir\\lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock C:\\Users\\Guillaume\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-2.7.8-64\\lock_dir\\lock\n"
     ]
    }
   ],
   "source": [
    "input_sequence = np.random.randn((T-1)*(D-1)).reshape((1, T-1, D-1))\n",
    "out = model.predict(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 160L, 63L)\n"
     ]
    }
   ],
   "source": [
    "print out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking that the output does not depend on \"future\" timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = 70\n",
    "disturbed_input_sequence = np.copy(input_sequence)\n",
    "disturbed_input_sequence[0, t0:] = 0.\n",
    "out2 = model.predict(disturbed_input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The t0 first values should'nt have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out!=out2)[0:120].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = reload(params)\n",
    "PATH_EXPERIMENT = params.PATH_EXPERIMENT\n",
    "NB_EPOCHS = params.NB_EPOCHS\n",
    "NB_SAMPLES_PER_EPOCH = params.NB_SAMPLES_PER_EPOCH\n",
    "PATIENCE = params.PATIENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainargs2strings(path, model, dataset, index_train, index_valid, D, batch_size, \n",
    "             nsamples_per_epoch, nepoch, patience): # see logging.py\n",
    "    settings = \"\"\n",
    "    settings += \"Path : %s\"%path\n",
    "    settings += \"\\nDataset shape :\" + str(dataset.shape)\n",
    "    settings += \"\\nNtrain : %d\"%len(index_train)\n",
    "    settings += \"\\nNvalid : %d\"%len(index_valid)\n",
    "    settings += \"\\nBatch size : %d\"%batch_size\n",
    "    settings += \"\\nNb samples per epoch : %d\"%nsamples_per_epoch\n",
    "    settings += \"\\nNb epochs : %d\"%nepoch\n",
    "    settings += \"\\nPatience : %d\"%patience\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(path, model, dataset, index_train, index_valid, D, batch_size, \n",
    "             nsamples_per_epoch, nepoch, patience): # see training.py\n",
    "    start = time.time()\n",
    "    # Create dir (if not already done)\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(os.path.abspath(path))\n",
    "    path_weights = os.path.join(path, \"weights\")\n",
    "    if os.path.exists(path_weights) is False:\n",
    "        os.mkdir(os.path.abspath(path_weights))\n",
    "    # Create log file\n",
    "    settings = trainargs2strings(path, model, dataset, index_train, index_valid, D, batch_size, \n",
    "                                 nsamples_per_epoch, nepoch, patience)\n",
    "    create_log(path, settings)\n",
    "    # Save architecture\n",
    "    save_architecture(model, path)\n",
    "    # Save weights after initialization\n",
    "    model.save_weights(os.path.join(path_weights, \"after_initialization.weights\"), \n",
    "                       overwrite=True)\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=patience)\n",
    "    model_saver = ModelSaver(path, os.path.join(path, \"weights\"), monitor=\"val_loss\")\n",
    "    # Argument to give to generators\n",
    "    train_generator_args = [dataset, index_train, batch_size, D]\n",
    "    valid_generator_args = [dataset, index_valid, batch_size, D]\n",
    "    # Training loop\n",
    "    h = model.fit_generator(batch_generator(*train_generator_args), nsamples_per_epoch, nepoch, \n",
    "                            validation_data=batch_generator(*valid_generator_args), \n",
    "                            nb_val_samples=len(index_valid),\n",
    "                            callbacks=[early_stopping, model_saver])\n",
    "\n",
    "    end = time.time()\n",
    "    print \"Training took %.2fs\"%(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick test\n",
    "b = 32 # batch size\n",
    "n = b*50 # number of examples in 1 epoch\n",
    "nepoch = 3 # number of epochs\n",
    "patience = 3 # patience\n",
    "\n",
    "training(\"experiments/causalCNN_debug\", model, DATASET, index_train, index_valid[0:(b*50)], D, \n",
    "         b, n, nepoch, patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Needs to be filled - Sampling functions - \"Temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w a t c h   m o r e   a w a y   f o r   # s i m p l e f i v e   w o m a n   3 ,   k e l l i e s   -   o n e   # d i n z s l i m m a r t a s   f o r   1 3   a n d   h e a d i n g   o f   k a r l a ,   1 0 7   # 5   a t   3 8 4 w p"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['watch more away for #simplefive woman 3, kellies - one #dinzslimmartas for 13 and heading of karla, 107 #5 at 384wp']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_character = \"w\"\n",
    "i = np.where(np.array(ACCEPTED_CHARS)==first_character)[0]\n",
    "\n",
    "sequence = np.zeros((1, T-1, D-1), \"float32\")\n",
    "sequence[0,0,i] = 1\n",
    "\n",
    "print first_character,\n",
    "for t in range(T-2):\n",
    "    out = model.predict(sequence)   \n",
    "    next_char = np.random.choice(range(D-1), p=out[0,t]/out[0,t].sum())\n",
    "    sequence[0,t+1,next_char] = 1\n",
    "    if next_char != 62:\n",
    "        char = ACCEPTED_CHARS[next_char]\n",
    "    else:\n",
    "        break\n",
    "    print char,\n",
    "    \n",
    "onehot2tweet(sequence, ACCEPTED_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
