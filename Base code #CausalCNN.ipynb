{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 850M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET = np.load(\"data/dataset.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (15075059L, 161L, 1L)\n"
     ]
    }
   ],
   "source": [
    "print \"Shape :\", DATASET.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into a trainset, a validset and a testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_rate=[0.94, 0.01, 0.04], seed=123): # see preprocessing.py\n",
    "    # index = 1,2,3,...,N\n",
    "    N = dataset.shape[0]\n",
    "    index = range(dataset.shape[0])\n",
    "    # shuffle\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(index)\n",
    "    # division\n",
    "    train_rate, valid_rate, test_rate = np.cumsum(split_rate)\n",
    "    index_train = index[0:int(train_rate*N)]\n",
    "    index_valid = index[int(train_rate*N):int(valid_rate*N)]\n",
    "    index_test = index[int(valid_rate*N):int(test_rate*N)]\n",
    "    # return \n",
    "    return index_train, index_valid, index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_train, index_valid, index_test = split_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**index_train, index_valid, index_test** are such that :\n",
    "\n",
    "trainset = DATASET[index_train]\n",
    "\n",
    "validset = DATASET[index_valid]\n",
    "\n",
    "testset = DATASET[index_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACCEPTED_CHARS = params.ACCEPTED_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x80', '\\x92', '\\x98', '\\x9f', '\\xa6', '\\xe2', '\\xf0']\n"
     ]
    }
   ],
   "source": [
    "print ACCEPTED_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch2onehot(batch, D): # see preprocessing.py\n",
    "    ''' Function used during the training to encode batches.\n",
    "    Input size : (batch_size, tweet_length, 1).\n",
    "    Output size : (batch_size, tweet_length, D)'''\n",
    "    B, T = batch.shape[0:2]\n",
    "    one_hot_batch = np.zeros((B*T, D))\n",
    "    one_hot_batch[range(B*T), batch.flatten()] = 1\n",
    "    one_hot_batch = one_hot_batch.reshape((B,T,D))\n",
    "    return one_hot_batch\n",
    "\n",
    "def batch2tweet(batch, accepted_caracters, special_char=\"\"): # see preprocessing.py\n",
    "    '''Not optimized. But not used during the training : no need to be fast.'''\n",
    "    tweets = []\n",
    "    for t in batch:\n",
    "        tweet = \"\"\n",
    "        for char in t:\n",
    "            try:\n",
    "                tweet += accepted_caracters[char[0]]\n",
    "            except:\n",
    "                tweet += special_char # Special marker indicating the end of the tweet\n",
    "        tweets.append(tweet)\n",
    "    return tweets\n",
    "\n",
    "def onehot2tweet(batch, accepted_caracters, special_char=\"\"): # see preprocessing.py\n",
    "    '''Not optimized. But not used during the training : no need to be fast.'''\n",
    "    tweets = []\n",
    "    for t in batch:\n",
    "        tweet = \"\"\n",
    "        for char in t:\n",
    "            try:\n",
    "                tweet += accepted_caracters[np.where(char==1)[0][0]]\n",
    "            except:\n",
    "                tweet += special_char # Special marker indicating the end of the tweet\n",
    "        tweets.append(tweet)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-61069acfb103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m  \u001b[1;31m# batch size for the demo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[1;31m# max length of a tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDATASET\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# Dataset > One-hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mone_hot_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch2onehot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATASET' is not defined"
     ]
    }
   ],
   "source": [
    "D = params.D  # dimension of one-hot vectors\n",
    "B = params.B  # batch size for the demo\n",
    "T = params.T  # max length of a tweet\n",
    "batch = DATASET[0:B] \n",
    "# Dataset > One-hot\n",
    "one_hot_batch = batch2onehot(batch, D)\n",
    "\n",
    "# Pick a tweet\n",
    "t = np.random.randint(B)\n",
    "# Pick a char\n",
    "c = np.random.randint(T)\n",
    "print \"Char %d from tweet %d :\"%(c,t), one_hot_batch[t][c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to, possible to go back in the \"string\" domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @c_throwed: obama the goat for this ðŸ’€\n",
      "\n",
      " https://t.co/gaznhjw7ry\n",
      "rt @c_throwed: obama the goat for this ðŸ’€\n",
      "\n",
      " https://t.co/gaznhjw7ry\n"
     ]
    }
   ],
   "source": [
    "# Using 'batch2tweet' :\n",
    "t = np.random.randint(B) # Pick a tweet\n",
    "print batch2tweet(batch, ACCEPTED_CHARS)[t]\n",
    "# or 'onehot2tweet' if the tweet has already been converted to onehot :\n",
    "print onehot2tweet(one_hot_batch, ACCEPTED_CHARS)[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, index, batch_size, D): # see preprocessing.py\n",
    "    # Init iterator and shuffling the dataset\n",
    "    count = 0\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        if count+batch_size >= len(index):\n",
    "            # Reset counter and shuffling\n",
    "            count = 0\n",
    "            np.random.shuffle(index)\n",
    "        # Get raw data\n",
    "        raw_batch = np.copy(data[index[count:(count+batch_size)]])\n",
    "        # One-hot encoding\n",
    "        one_hot_batch = batch2onehot(raw_batch, D)\n",
    "        # Remove the padding dimension\n",
    "        one_hot_batch = one_hot_batch[:,:,0:(D-1)] # s.t. padding features are full of 0s\n",
    "                                                   # and will be masked by the Masking layer\n",
    "                                                   # (see below in the model definition)\n",
    "        # Target\n",
    "        input_batch  = one_hot_batch[:, 0:-1, :]\n",
    "        target_batch = one_hot_batch[:, 1:, :] # target = 1-shifted input batch\n",
    "        del raw_batch\n",
    "        count += batch_size\n",
    "        # Yield\n",
    "        yield input_batch, target_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions used to save stuff..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save_architecture** : save the architecture of the model in a text file.\n",
    "\n",
    "**create_log** : create a text file where the loss, and other metrics will be printed using **write_log**\n",
    "\n",
    "**ModelSaver** : Custom Keras callback (https://keras.io/callbacks/). This object is given to the 'fit' (or equivalently 'fit_generator') when launching a training. It permits to control when to save weights, and underwhich name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_architecture(model, path_out): # see logging.py\n",
    "    \"\"\"\n",
    "    Based on the keras utils 'model.summary()'\n",
    "    \"\"\"\n",
    "    # Redirect the print output the a textfile\n",
    "    orig_stdout = sys.stdout\n",
    "    # and store the architecture\n",
    "    f = file(os.path.join(path_out, \"architecture.txt\"), 'w')\n",
    "    sys.stdout = f\n",
    "    model.summary()\n",
    "    # Reset the print output direction\n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "\n",
    "    open(os.path.join(path_out, \"config.json\"), 'w').write(model.to_json())\n",
    "\n",
    "\n",
    "def create_log(path, settings, filename=\"log.txt\"): # see logging.py\n",
    "    f = open(os.path.join(path, filename), \"w\")\n",
    "    f.writelines(str(settings))\n",
    "    f.writelines(\"\\n####\\nStarted on %s at %s\\n\" % (time.strftime(\"%d/%m/%Y\"), time.strftime(\"%H:%M:%S\")))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def write_log(path, string, filename=\"log.txt\"): # see logging.py\n",
    "    \"\"\"\n",
    "    Add a line at the end of a textfile.\n",
    "\n",
    "    :param path: textfile location\n",
    "    :param string: line to add\n",
    "    \"\"\"\n",
    "    # Open and Read\n",
    "    f = open(os.path.join(path, filename), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    # Adding a line\n",
    "    lines.append(string)\n",
    "    # Write\n",
    "    f = open(os.path.join(path, filename), \"w\")\n",
    "    f.writelines(lines)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "    \n",
    "class ModelSaver(Callback): # see logging.py\n",
    "    \"\"\"\n",
    "    Keras callback subclass which defines a saving procedure of the model being trained : after each epoch,\n",
    "    the last model is saved under the name 'after_random.cnn'. The best model is saved with the name 'best_model.cnn'.\n",
    "    The model after random can also be saved. And the model architecture is saved with the name 'config.network'.\n",
    "    Everything is stored using pickle.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, path_weights, monitor, verbose=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.path_weights = path_weights\n",
    "        self.monitor = monitor\n",
    "        self.best = np.Inf\n",
    "        \n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_end = time.time()\n",
    "        # get loss\n",
    "        monitor = logs.get(self.monitor)\n",
    "        # condition = True if loss decreased\n",
    "        condition = monitor < self.best\n",
    "\n",
    "        if condition:\n",
    "            # Save weights as \"best_model.weights\"\n",
    "            self.best = monitor\n",
    "            save_path = os.path.join(self.path_weights, \"best_model.weights\")\n",
    "            self.model.save_weights(save_path, overwrite=True)\n",
    "        else:\n",
    "            # Save weights as \"last_epoch.weights\"\n",
    "            save_path = os.path.join(self.path_weights, \"last_epoch.weights\")\n",
    "            self.model.save_weights(save_path, overwrite=True)\n",
    "        \n",
    "        # Log file management\n",
    "        if self.verbose > 0:\n",
    "            log_string = \"####\\nEpoch %d took %d s: \" % (epoch, int(self.epoch_end-self.epoch_start))\n",
    "            for k in logs.keys():\n",
    "                log_string += \"%s : %.4f # \" % (k, logs.get(k))\n",
    "            if condition:\n",
    "                log_string += \"\\tBEST\"\n",
    "            write_log(self.path, log_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, TimeDistributed, Dense, Activation, ZeroPadding1D, AtrousConvolution1D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CausalConvolution1D(input_layer, nfilters, filter_length, atrous_rate=1, activation=\"linear\", **kwargs):\n",
    "    total_length = filter_length + (filter_length-1)*(atrous_rate-1)\n",
    "    # Asymetric padding : 0 added only on the left side\n",
    "    padd = ZeroPadding1D((total_length-1,0))(input_layer)\n",
    "    # Convolution\n",
    "    conv = AtrousConvolution1D(nfilters, filter_length, atrous_rate=atrous_rate, border_mode='valid', **kwargs)(padd)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    activ = Activation(activation)(bn)\n",
    "    # Return\n",
    "    return activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(T, D, lr, nhidden, drop_rate): # see models.py\n",
    "    # Input layer\n",
    "    inputs = Input((T, D))\n",
    "    # Masking \"only-0\" input features : ZeroPadding do not support Masking\n",
    "    # masked = Masking(mask_value=0.0)(inputs)\n",
    "    # Hidden layers\n",
    "    for i in range(10):\n",
    "        if i == 0:\n",
    "            hidden  = CausalConvolution1D(inputs, 128, 11, atrous_rate=1, activation=\"relu\")\n",
    "        else:\n",
    "            hidden  = CausalConvolution1D(dropout, 128, 11, atrous_rate=1, activation=\"relu\")\n",
    "        dropout = Dropout(drop_rate)(hidden)\n",
    "    # Output layer : linear TimeDistributedDense + softmax\n",
    "    decoder = TimeDistributed(Dense(D))(dropout) # Apply the same dense layer on each timestep\n",
    "    outputs = Activation(\"softmax\") (decoder)\n",
    "\n",
    "    model = Model(input=inputs, output=outputs)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss=\"categorical_crossentropy\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = params.LR # learning rate\n",
    "model = get_model(T-1, D-1, LR, 3, 0.1) # D-1 because params.D accounts for the padding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 160, 63)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_12 (ZeroPadding1D) (None, 170, 63)       0           input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_12 (AtrousCon(None, 160, 128)      88832       zeropadding1d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 160, 128)      0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 160, 128)      0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_13 (ZeroPadding1D) (None, 170, 128)      0           dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_13 (AtrousCon(None, 160, 128)      180352      zeropadding1d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 160, 128)      0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 160, 128)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_14 (ZeroPadding1D) (None, 170, 128)      0           dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_14 (AtrousCon(None, 160, 128)      180352      zeropadding1d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 160, 128)      0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 160, 128)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_15 (ZeroPadding1D) (None, 170, 128)      0           dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_15 (AtrousCon(None, 160, 128)      180352      zeropadding1d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 160, 128)      0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 160, 128)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_16 (ZeroPadding1D) (None, 170, 128)      0           dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_16 (AtrousCon(None, 160, 128)      180352      zeropadding1d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 160, 128)      0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 160, 128)      0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_17 (ZeroPadding1D) (None, 170, 128)      0           dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_17 (AtrousCon(None, 160, 128)      180352      zeropadding1d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 160, 128)      0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 160, 128)      0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_18 (ZeroPadding1D) (None, 170, 128)      0           dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_18 (AtrousCon(None, 160, 128)      180352      zeropadding1d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 160, 128)      0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 160, 128)      0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_19 (ZeroPadding1D) (None, 170, 128)      0           dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_19 (AtrousCon(None, 160, 128)      180352      zeropadding1d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 160, 128)      0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 160, 128)      0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_20 (ZeroPadding1D) (None, 170, 128)      0           dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_20 (AtrousCon(None, 160, 128)      180352      zeropadding1d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNormal(None, 160, 128)      256         atrousconvolution1d_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 160, 128)      0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 160, 128)      0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding1d_21 (ZeroPadding1D) (None, 170, 128)      0           dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution1d_21 (AtrousCon(None, 160, 128)      180352      zeropadding1d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorma(None, 160, 128)      256         atrousconvolution1d_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 160, 128)      0           batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 160, 128)      0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribute(None, 160, 63)       8127        dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 160, 63)       0           timedistributed_2[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1722687\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Guillaume\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-2.7.8-64\\lock_dir\\lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock C:\\Users\\Guillaume\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-2.7.8-64\\lock_dir\\lock\n"
     ]
    }
   ],
   "source": [
    "input_sequence = np.random.randn((T-1)*(D-1)).reshape((1, T-1, D-1))\n",
    "out = model.predict(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 160L, 63L)\n"
     ]
    }
   ],
   "source": [
    "print out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking that the output does not depend on \"future\" timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = 70\n",
    "disturbed_input_sequence = np.copy(input_sequence)\n",
    "disturbed_input_sequence[0, t0:] = 0.\n",
    "out2 = model.predict(disturbed_input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The t0 first values should'nt have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out!=out2)[0:120].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = reload(params)\n",
    "PATH_EXPERIMENT = params.PATH_EXPERIMENT\n",
    "NB_EPOCHS = params.NB_EPOCHS\n",
    "NB_SAMPLES_PER_EPOCH = params.NB_SAMPLES_PER_EPOCH\n",
    "PATIENCE = params.PATIENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainargs2strings(path, model, dataset, index_train, index_valid, D, batch_size, \n",
    "             nsamples_per_epoch, nepoch, patience): # see logging.py\n",
    "    settings = \"\"\n",
    "    settings += \"Path : %s\"%path\n",
    "    settings += \"\\nDataset shape :\" + str(dataset.shape)\n",
    "    settings += \"\\nNtrain : %d\"%len(index_train)\n",
    "    settings += \"\\nNvalid : %d\"%len(index_valid)\n",
    "    settings += \"\\nBatch size : %d\"%batch_size\n",
    "    settings += \"\\nNb samples per epoch : %d\"%nsamples_per_epoch\n",
    "    settings += \"\\nNb epochs : %d\"%nepoch\n",
    "    settings += \"\\nPatience : %d\"%patience\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(path, model, dataset, index_train, index_valid, D, batch_size, \n",
    "             nsamples_per_epoch, nepoch, patience): # see training.py\n",
    "    start = time.time()\n",
    "    # Create dir (if not already done)\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(os.path.abspath(path))\n",
    "    path_weights = os.path.join(path, \"weights\")\n",
    "    if os.path.exists(path_weights) is False:\n",
    "        os.mkdir(os.path.abspath(path_weights))\n",
    "    # Create log file\n",
    "    settings = trainargs2strings(path, model, dataset, index_train, index_valid, D, batch_size, \n",
    "                                 nsamples_per_epoch, nepoch, patience)\n",
    "    create_log(path, settings)\n",
    "    # Save architecture\n",
    "    save_architecture(model, path)\n",
    "    # Save weights after initialization\n",
    "    model.save_weights(os.path.join(path_weights, \"after_initialization.weights\"), \n",
    "                       overwrite=True)\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=patience)\n",
    "    model_saver = ModelSaver(path, os.path.join(path, \"weights\"), monitor=\"val_loss\")\n",
    "    # Argument to give to generators\n",
    "    train_generator_args = [dataset, index_train, batch_size, D]\n",
    "    valid_generator_args = [dataset, index_valid, batch_size, D]\n",
    "    # Training loop\n",
    "    h = model.fit_generator(batch_generator(*train_generator_args), nsamples_per_epoch, nepoch, \n",
    "                            validation_data=batch_generator(*valid_generator_args), \n",
    "                            nb_val_samples=len(index_valid),\n",
    "                            callbacks=[early_stopping, model_saver])\n",
    "\n",
    "    end = time.time()\n",
    "    print \"Training took %.2fs\"%(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick test\n",
    "b = 32 # batch size\n",
    "n = b*50 # number of examples in 1 epoch\n",
    "nepoch = 3 # number of epochs\n",
    "patience = 3 # patience\n",
    "\n",
    "training(\"experiments/causalCNN_debug\", model, DATASET, index_train, index_valid[0:(b*50)], D, \n",
    "         b, n, nepoch, patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Needs to be filled - Sampling functions - \"Temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"experiments/causalCNN_10x_kernel11_128n_BN/weights/best_model.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t h a n k   y o u   i s   a   b u n t o b i z a n i a   c o m e s s a   u n c i l k s   m u s i c   b y   p r i n c e s s   i ' l l   b e   w o r k i n g   f o r   u n t h l e s s d o n c e s s i o n   # h e r t e r s   # i n r a n t p t r e   h t t p s : / / t . c o / 3 j 5 m r t z r c 9   h t t p s : / / ï¿½ ï¿½ ï¿½"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"thank you is a buntobizania comessa uncilks music by princess i'll be working for unthlessdoncession #herters #inrantptre https://t.co/3j5mrtzrc9 https://\\xe2\\x80\\xa6\"]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_character = \"t\"\n",
    "i = np.where(np.array(ACCEPTED_CHARS)==first_character)[0]\n",
    "\n",
    "sequence = np.zeros((1, T-1, D-1), \"float32\")\n",
    "sequence[0,0,i] = 1\n",
    "\n",
    "print first_character,\n",
    "for t in range(T-2):\n",
    "    out = model.predict(sequence)   \n",
    "    out = out.astype(\"float64\")\n",
    "    next_char = np.random.choice(range(D-1), p=(out[0,t]/out[0,t].sum()))\n",
    "    sequence[0,t+1,next_char] = 1\n",
    "    if next_char != 62:\n",
    "        char = ACCEPTED_CHARS[next_char]\n",
    "    else:\n",
    "        break\n",
    "    print char,\n",
    "    \n",
    "onehot2tweet(sequence, ACCEPTED_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
